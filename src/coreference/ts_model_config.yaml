# See all available options at the url below
# https://github.com/pytorch/serve/blob/master/frontend/archive/src/main/java/org/pytorch/serve/archive/model/ModelConfig.java
minWorkers: 1
maxWorkers: 1
batchSize: 8
maxBatchDelay: 100
responseTimeout: 120
maxRetryTimeoutInSec: 300
jobQueueSize: 200
deviceType: gpu
# useJobTicket: False
# sequenceMaxIdleMSec: 0
# maxSequenceJobQueueSize: 1
# maxNumSequence: 1
# continuousBatching: True
